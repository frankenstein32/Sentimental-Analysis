{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, SimpleRNN,LSTM, Activation\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_emoji data and test emoji data is Attached in the repo\n",
    "train = pd.read_csv('train_emoji.csv',header=None)\n",
    "test = pd.read_csv('test_emoji.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the data by printing first 5 entries\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want to eat\\t</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he did not answer\\t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he got a raise\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she got me a present\\t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ha ha ha it was so funny\\t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0  1\n",
       "0             I want to eat\\t  4\n",
       "1         he did not answer\\t  3\n",
       "2            he got a raise\\t  2\n",
       "3      she got me a present\\t  0\n",
       "4  ha ha ha it was so funny\\t  2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the data by printing first 5 entries\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Dictionary of some emoji's with key a number and value is emoji\n",
    "emoji_dict = { 0 : \":heart:\", 1 : \":baseball:\", 2:\":smile:\", 3 : \":disappointed:\", 4 : \":fork_and_knife:\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ‚ù§\n",
      "1 ‚öæ\n",
      "2 üòÑ\n",
      "3 üòû\n",
      "4 üç¥\n"
     ]
    }
   ],
   "source": [
    "# printing the emoji icon by emojifying each emoji\n",
    "for ix in emoji_dict.keys():\n",
    "    print(ix,end=\" \")\n",
    "    print (emoji.emojize(emoji_dict[ix], use_aliases=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132,) (132,) (56,) (56,)\n",
      "-------------------------\n",
      "never talk to me again 3\n"
     ]
    }
   ],
   "source": [
    "# Creating the training and testing data\n",
    "\n",
    "X_train = train[0]\n",
    "Y_train = train[1]\n",
    "\n",
    "X_test = test[0]\n",
    "Y_test = test[1]\n",
    "\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n",
    "print((\"-------------------------\"))\n",
    "print(X_train[0],Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c1030d759a21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# Splitting the train data from sentences to list of words\n",
    "for ix in range(X_train.shape[0]):\n",
    "    X_train[ix] = X_train[ix].split()\n",
    "    \n",
    "# Splitting the test data from sentences to list of words\n",
    "for ix in range(X_test.shape[0]):\n",
    "    X_test[ix] = X_test[ix].split()\n",
    "\n",
    "# Converting the labels into categorical Form\n",
    "Y_train = np_utils.to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never', 'talk', 'to', 'me', 'again'] [0. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train[0],Y_train[0])\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       " array([ 4,  5, 26, 35, 20, 21, 11,  5,  1,  4]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check what's the maximum length exist in the training data\n",
    "np.unique(np.array([len(ix) for ix in X_train]) , return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 3, 4, 5, 6, 7, 8]), array([ 3, 12, 16, 17,  3,  4,  1]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check what's the maximum length exist in the testing data\n",
    "np.unique(np.array([len(ix) for ix in X_test]) , return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Embedding dictionary with key = word and value = list of words\n",
    "embeddings_index = {}\n",
    "\n",
    "f = open('glove.6B.50d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "#     print(values)\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the length of each vector\n",
    "embeddings_index[\"i\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31093674898147583"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Scipy library to import the embedding matrix\n",
    "from scipy import spatial\n",
    "\n",
    "# Checking the cosine similarity of happy and sad\n",
    "spatial.distance.cosine(embeddings_index[\"happy\"], embeddings_index[\"sad\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18572336435317993"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the cosine similarity of india and delhi\n",
    "spatial.distance.cosine(embeddings_index[\"india\"], embeddings_index[\"delhi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19746702909469604"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the cosine similarity of france and paris\n",
    "spatial.distance.cosine(embeddings_index[\"france\"], embeddings_index[\"paris\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the Embedding Matrix\n",
    "\n",
    "embedding_matrix_train = np.zeros((X_train.shape[0], 10, 50))\n",
    "embedding_matrix_test = np.zeros((X_test.shape[0], 10, 50))\n",
    "\n",
    "for ix in range(X_train.shape[0]):\n",
    "    for ij in range(len(X_train[ix])):\n",
    "        embedding_matrix_train[ix][ij] = embeddings_index[X_train[ix][ij].lower()]\n",
    "        \n",
    "for ix in range(X_test.shape[0]):\n",
    "    for ij in range(len(X_test[ix])):\n",
    "        embedding_matrix_test[ix][ij] = embeddings_index[X_test[ix][ij].lower()]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 10, 50) (56, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix_train.shape, embedding_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_3 (SimpleRNN)     (None, 10, 64)            7360      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_4 (SimpleRNN)     (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 15,941\n",
      "Trainable params: 15,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A simple RNN network to classify the emoji class from a input Sentence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(64, input_shape=(10,50), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(SimpleRNN(64, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Loss, Optimizer of the Model \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 1s 5ms/step - loss: 1.8833 - acc: 0.2500\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 476us/step - loss: 1.7785 - acc: 0.2197\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 489us/step - loss: 1.6567 - acc: 0.2955\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 509us/step - loss: 1.6565 - acc: 0.2273\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 498us/step - loss: 1.5134 - acc: 0.3561\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 546us/step - loss: 1.5075 - acc: 0.3636\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 639us/step - loss: 1.5513 - acc: 0.3712\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 519us/step - loss: 1.4025 - acc: 0.4091\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 543us/step - loss: 1.3645 - acc: 0.4773\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 621us/step - loss: 1.3342 - acc: 0.4318\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 524us/step - loss: 1.1918 - acc: 0.5152\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 484us/step - loss: 1.1895 - acc: 0.5985\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 460us/step - loss: 1.1314 - acc: 0.5682\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 420us/step - loss: 1.1472 - acc: 0.5606\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 569us/step - loss: 1.0883 - acc: 0.5606\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 449us/step - loss: 1.0370 - acc: 0.6591\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 625us/step - loss: 1.0293 - acc: 0.6515\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 584us/step - loss: 1.0411 - acc: 0.6439\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 508us/step - loss: 0.9862 - acc: 0.6591\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 684us/step - loss: 0.9629 - acc: 0.6591\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 685us/step - loss: 0.8324 - acc: 0.7348\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 571us/step - loss: 0.9396 - acc: 0.6742\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 698us/step - loss: 0.9096 - acc: 0.6364\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 854us/step - loss: 0.8568 - acc: 0.6364\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 770us/step - loss: 0.8531 - acc: 0.7121\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 606us/step - loss: 0.7460 - acc: 0.7273\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 710us/step - loss: 0.8048 - acc: 0.7197\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 720us/step - loss: 0.7026 - acc: 0.7727\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 580us/step - loss: 0.7290 - acc: 0.7500\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 597us/step - loss: 0.6612 - acc: 0.8030\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 591us/step - loss: 0.5972 - acc: 0.8258\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 351us/step - loss: 0.6428 - acc: 0.7576\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 632us/step - loss: 0.5381 - acc: 0.8258\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 663us/step - loss: 0.5522 - acc: 0.8182\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 586us/step - loss: 0.4998 - acc: 0.8712\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 671us/step - loss: 0.4743 - acc: 0.8561\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 568us/step - loss: 0.4739 - acc: 0.8561\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 535us/step - loss: 0.4693 - acc: 0.8561\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 580us/step - loss: 0.4484 - acc: 0.8636\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 522us/step - loss: 0.3777 - acc: 0.9015\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 596us/step - loss: 0.4033 - acc: 0.8864\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 539us/step - loss: 0.3680 - acc: 0.9167\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 612us/step - loss: 0.3740 - acc: 0.8864\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 431us/step - loss: 0.2816 - acc: 0.9318\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 638us/step - loss: 0.3606 - acc: 0.9015\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 631us/step - loss: 0.2806 - acc: 0.9318\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 517us/step - loss: 0.2706 - acc: 0.9167\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 567us/step - loss: 0.2425 - acc: 0.9470\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 499us/step - loss: 0.2036 - acc: 0.9697\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 642us/step - loss: 0.2488 - acc: 0.9091\n"
     ]
    }
   ],
   "source": [
    "# Training of the Model\n",
    "\n",
    "hist = model.fit(embedding_matrix_train,Y_train,\n",
    "                epochs = 50, batch_size=32,shuffle=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction from the trained model\n",
    "pred = model.predict_classes(embedding_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the score of the algorithm\n",
    "\n",
    "float(sum(pred==Y_test))/embedding_matrix_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "['she', 'got', 'me', 'a', 'present'] üòÑ ‚ù§\n",
      "6\n",
      "['I', 'am', 'upset'] üòû ‚ù§\n",
      "7\n",
      "['We', 'had', 'such', 'a', 'lovely', 'dinner', 'tonight'] üç¥ ‚ù§\n",
      "12\n",
      "['This', 'girl', 'is', 'messing', 'with', 'me'] ‚ù§ üòû\n",
      "13\n",
      "['are', 'you', 'serious', 'ha', 'ha'] üòû üòÑ\n",
      "15\n",
      "['This', 'stupid', 'grader', 'is', 'not', 'working'] üòÑ üòû\n",
      "18\n",
      "['stop', 'messing', 'around'] ‚ù§ üòû\n",
      "20\n",
      "['I', 'love', 'taking', 'breaks'] üç¥ ‚ù§\n",
      "21\n",
      "['you', 'brighten', 'my', 'day'] üç¥ üòÑ\n",
      "23\n",
      "['she', 'is', 'a', 'bully'] ‚ù§ üòû\n",
      "26\n",
      "['I', 'worked', 'during', 'my', 'birthday'] üòÑ üòû\n",
      "27\n",
      "['My', 'grandmother', 'is', 'the', 'love', 'of', 'my', 'life'] üòû ‚ù§\n",
      "28\n",
      "['enjoy', 'your', 'break'] ‚ù§ üòÑ\n",
      "29\n",
      "['valentine', 'day', 'is', 'near'] üòÑ ‚ù§\n",
      "32\n",
      "['My', 'life', 'is', 'so', 'boring'] üòÑ üòû\n",
      "35\n",
      "['he', 'can', 'pitch', 'really', 'well'] üòû ‚öæ\n",
      "36\n",
      "['dance', 'with', 'me'] üòû üòÑ\n",
      "38\n",
      "['See', 'you', 'at', 'the', 'restaurant'] üòÑ üç¥\n",
      "40\n",
      "['I', 'will', 'go', 'dance'] ‚öæ üòÑ\n",
      "41\n",
      "['I', 'like', 'your', 'jacket'] ‚ù§ üòÑ\n",
      "45\n",
      "['I', 'love', 'to', 'the', 'stars', 'and', 'back'] üòû ‚ù§\n",
      "46\n",
      "['What', 'you', 'did', 'was', 'awesome'] ‚öæ üòÑ\n",
      "48\n",
      "['I', 'want', 'to', 'joke'] ‚ù§ üòÑ\n",
      "49\n",
      "['go', 'away'] üç¥ üòû\n",
      "50\n",
      "['yesterday', 'we', 'lost', 'again'] ‚öæ üòû\n",
      "51\n",
      "['family', 'is', 'all', 'I', 'have'] üòû ‚ù§\n",
      "52\n",
      "['you', 'are', 'failing', 'this', 'exercise'] üòÑ üòû\n",
      "54\n",
      "['You', 'totally', 'deserve', 'this', 'prize'] üòû üòÑ\n"
     ]
    }
   ],
   "source": [
    "# printing the sentences with the predicted emoji and the labelled emoji\n",
    "\n",
    "for ix in range(embedding_matrix_test.shape[0]):\n",
    "    \n",
    "    if pred[ix] != Y_test[ix]:\n",
    "        print(ix)\n",
    "        print(test[0][ix],end=\" \")\n",
    "        print(emoji.emojize(emoji_dict[pred[ix]], use_aliases=True),end=\" \")\n",
    "        print(emoji.emojize(emoji_dict[Y_test[ix]], use_aliases=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for Our random sentence\n",
    "\n",
    "x = ['i', 'do', 'think','this', 'class', 'is', 'very', 'interesting']\n",
    "\n",
    "x_ = np.zeros((1,10,50))\n",
    "\n",
    "for ix in range(len(x)):\n",
    "    x_[0][ix] = embeddings_index[x[ix].lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(x_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 223,877\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(10,50), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 2s 13ms/step - loss: 1.5877 - acc: 0.2652\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.5185 - acc: 0.3333\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.4466 - acc: 0.4167\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 1.4128 - acc: 0.4394\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 1.3376 - acc: 0.4242\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 1.2094 - acc: 0.5606\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 1.0628 - acc: 0.6364\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 1.0022 - acc: 0.6136\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.8686 - acc: 0.6591\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.8543 - acc: 0.6894\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.6672 - acc: 0.7727\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.6450 - acc: 0.7348\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.5501 - acc: 0.8182\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.5672 - acc: 0.7803\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.5747 - acc: 0.8030\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4663 - acc: 0.8258\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3831 - acc: 0.8561\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4661 - acc: 0.8182\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3328 - acc: 0.8939\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3092 - acc: 0.8939\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3501 - acc: 0.9015\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2682 - acc: 0.9091\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2879 - acc: 0.9091\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2337 - acc: 0.9318\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2166 - acc: 0.9167\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2082 - acc: 0.9318\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2157 - acc: 0.9091\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1708 - acc: 0.9470\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1480 - acc: 0.9470\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1136 - acc: 0.9621\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1200 - acc: 0.9545\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.0770 - acc: 0.9697\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0564 - acc: 0.9848\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0654 - acc: 0.9848\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0411 - acc: 0.9924\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0911 - acc: 0.9621\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0650 - acc: 0.9697\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1706 - acc: 0.9621\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0690 - acc: 0.9848\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0749 - acc: 0.9621\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2765 - acc: 0.9091\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1009 - acc: 0.9697\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2411 - acc: 0.8864\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.4099 - acc: 0.8333\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1979 - acc: 0.9470\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1634 - acc: 0.9470\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.2605 - acc: 0.8939\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1493 - acc: 0.9545\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1332 - acc: 0.9697\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 3ms/step - loss: 0.1088 - acc: 0.9773\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(embedding_matrix_train,Y_train,\n",
    "                epochs = 50, batch_size=32,shuffle=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(embedding_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(sum(pred==Y_test))/embedding_matrix_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['he', 'got', 'a', 'raise'] üòû üòÑ\n",
      "3\n",
      "['she', 'got', 'me', 'a', 'present'] üòÑ ‚ù§\n",
      "5\n",
      "['he', 'is', 'a', 'good', 'friend'] üòÑ ‚ù§\n",
      "6\n",
      "['I', 'am', 'upset'] üòû ‚ù§\n",
      "7\n",
      "['We', 'had', 'such', 'a', 'lovely', 'dinner', 'tonight'] üòÑ ‚ù§\n",
      "11\n",
      "['work', 'is', 'hard'] üòÑ üòû\n",
      "12\n",
      "['This', 'girl', 'is', 'messing', 'with', 'me'] ‚ù§ üòû\n",
      "13\n",
      "['are', 'you', 'serious', 'ha', 'ha'] üòû üòÑ\n",
      "18\n",
      "['stop', 'messing', 'around'] ‚öæ üòû\n",
      "20\n",
      "['I', 'love', 'taking', 'breaks'] üòû ‚ù§\n",
      "21\n",
      "['you', 'brighten', 'my', 'day'] ‚ù§ üòÑ\n",
      "23\n",
      "['she', 'is', 'a', 'bully'] ‚ù§ üòû\n",
      "26\n",
      "['I', 'worked', 'during', 'my', 'birthday'] üòÑ üòû\n",
      "28\n",
      "['enjoy', 'your', 'break'] üòû üòÑ\n",
      "29\n",
      "['valentine', 'day', 'is', 'near'] üòÑ ‚ù§\n",
      "32\n",
      "['My', 'life', 'is', 'so', 'boring'] ‚ù§ üòû\n",
      "40\n",
      "['I', 'will', 'go', 'dance'] ‚öæ üòÑ\n",
      "41\n",
      "['I', 'like', 'your', 'jacket'] ‚ù§ üòÑ\n",
      "49\n",
      "['go', 'away'] ‚öæ üòû\n",
      "54\n",
      "['You', 'totally', 'deserve', 'this', 'prize'] üòû üòÑ\n",
      "55\n",
      "['I', 'did', 'not', 'have', 'breakfast'] üç¥ üòû\n"
     ]
    }
   ],
   "source": [
    "for ix in range(embedding_matrix_test.shape[0]):\n",
    "    \n",
    "    if pred[ix] != Y_test[ix]:\n",
    "        print(ix)\n",
    "        print(test[0][ix],end=\" \")\n",
    "        print(emoji.emojize(emoji_dict[pred[ix]], use_aliases=True),end=\" \")\n",
    "        print(emoji.emojize(emoji_dict[Y_test[ix]], use_aliases=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
